---
title: Exploring 311 data with PCA
author: Conor Tompkins
date: '2018-07-19'
slug: exploring-311-data-with-pca
categories:
  - Pittsburgh
  - R
tags:
  - '311'
  - R Markdown
  - PCA
draft: false
---



<div id="principal-component-analysis-in-r" class="section level1">
<h1>Principal Component Analysis in R</h1>
<p>Principle Component Analysis is an unsupervised method that reduces the number of dimensions in a dataset and highlights where the data varies. We will use PCA to analyze the 311 dataset from the <a href="https://data.wprdc.org/dataset/311-data">WPRDC</a>.</p>
<div id="setup" class="section level2">
<h2>Setup</h2>
<div id="install-packages" class="section level3">
<h3>Install packages</h3>
<pre class="r"><code>install.packages(c(&quot;tidyverse&quot;, &quot;lubridate&quot;, &quot;broom&quot;, &quot;ggfortify&quot;, &quot;ggrepel&quot;, &quot;janitor&quot;))</code></pre>
</div>
<div id="set-up-your-environment" class="section level3">
<h3>Set up your environment</h3>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(broom)
library(ggfortify)
library(ggrepel)
library(janitor)

options(scipen = 999, digits = 4)
set.seed(1234)

theme_set(theme_bw())</code></pre>
</div>
</div>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<pre class="r"><code>read_csv(&quot;https://raw.githubusercontent.com/conorotompkins/pittsburgh_311/master/data/pittsburgh_311.csv&quot;, progress = FALSE) %&gt;% 
  clean_names() %&gt;% 
  mutate(date = ymd(str_sub(created_on, 1, 10)),
         month = month(date, label = TRUE)) -&gt; df</code></pre>
</div>
<div id="prep-the-data" class="section level2">
<h2>Prep the data</h2>
<p>Create a dataframe of the top request types</p>
<pre class="r"><code>(df %&gt;% 
  count(request_type, sort = TRUE) %&gt;% 
  filter(n &gt; 400) -&gt; df_top_requests)</code></pre>
<pre><code>## # A tibble: 84 x 2
##    request_type                             n
##    &lt;chr&gt;                                &lt;int&gt;
##  1 Potholes                             25202
##  2 Weeds/Debris                         16503
##  3 Building Maintenance                 10469
##  4 Snow/Ice removal                      7006
##  5 Refuse Violations                     6515
##  6 Abandoned Vehicle (parked on street)  5877
##  7 Missed Pick Up                        4689
##  8 Replace/Repair a Sign                 4445
##  9 Building Without a Permit             4404
## 10 Litter                                4198
## # ... with 74 more rows</code></pre>
<p>Count the number of requests per month by request type, filter for the top request types, fill in gaps in the data</p>
<pre class="r"><code>(df %&gt;%
  semi_join(df_top_requests) %&gt;% 
  group_by(request_type, month) %&gt;% 
  summarize(n = n()) %&gt;% 
  complete(request_type, month) %&gt;% 
  replace_na(replace = list(n = 0)) -&gt; df_months)</code></pre>
<pre><code>## # A tibble: 1,008 x 3
## # Groups:   request_type [84]
##    request_type                         month     n
##    &lt;chr&gt;                                &lt;ord&gt; &lt;dbl&gt;
##  1 Abandoned Vehicle (parked on street) Jan     523
##  2 Abandoned Vehicle (parked on street) Feb     427
##  3 Abandoned Vehicle (parked on street) Mar     452
##  4 Abandoned Vehicle (parked on street) Apr     417
##  5 Abandoned Vehicle (parked on street) May     488
##  6 Abandoned Vehicle (parked on street) Jun     466
##  7 Abandoned Vehicle (parked on street) Jul     457
##  8 Abandoned Vehicle (parked on street) Aug     596
##  9 Abandoned Vehicle (parked on street) Sep     525
## 10 Abandoned Vehicle (parked on street) Oct     571
## # ... with 998 more rows</code></pre>
<p>Calculate the percentage of a request type for each month</p>
<pre class="r"><code>(df_months %&gt;% 
  group_by(request_type) %&gt;% 
  mutate(request_type_total = sum(n),
         month_percentage = n / request_type_total) -&gt; df_months)</code></pre>
<pre><code>## # A tibble: 1,008 x 5
## # Groups:   request_type [84]
##    request_type             month     n request_type_tot~ month_percentage
##    &lt;chr&gt;                    &lt;ord&gt; &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;
##  1 Abandoned Vehicle (park~ Jan     523              5877           0.0890
##  2 Abandoned Vehicle (park~ Feb     427              5877           0.0727
##  3 Abandoned Vehicle (park~ Mar     452              5877           0.0769
##  4 Abandoned Vehicle (park~ Apr     417              5877           0.0710
##  5 Abandoned Vehicle (park~ May     488              5877           0.0830
##  6 Abandoned Vehicle (park~ Jun     466              5877           0.0793
##  7 Abandoned Vehicle (park~ Jul     457              5877           0.0778
##  8 Abandoned Vehicle (park~ Aug     596              5877           0.101 
##  9 Abandoned Vehicle (park~ Sep     525              5877           0.0893
## 10 Abandoned Vehicle (park~ Oct     571              5877           0.0972
## # ... with 998 more rows</code></pre>
<p>Check for bad data</p>
<pre class="r"><code>df_months %&gt;% 
  filter(is.na(month_percentage))</code></pre>
<pre><code>## # A tibble: 0 x 5
## # Groups:   request_type [0]
## # ... with 5 variables: request_type &lt;chr&gt;, month &lt;ord&gt;, n &lt;dbl&gt;,
## #   request_type_total &lt;dbl&gt;, month_percentage &lt;dbl&gt;</code></pre>
<pre class="r"><code>df_months %&gt;% 
  filter(is.nan(month_percentage))</code></pre>
<pre><code>## # A tibble: 0 x 5
## # Groups:   request_type [0]
## # ... with 5 variables: request_type &lt;chr&gt;, month &lt;ord&gt;, n &lt;dbl&gt;,
## #   request_type_total &lt;dbl&gt;, month_percentage &lt;dbl&gt;</code></pre>
<p>Spread the data to turn the months into the columns</p>
<pre class="r"><code>(df_months %&gt;% 
  select(request_type, month, month_percentage) %&gt;% 
  spread(month, month_percentage) %&gt;% 
  ungroup() -&gt; df_months)</code></pre>
<pre><code>## # A tibble: 84 x 13
##    request_type      Jan     Feb    Mar    Apr    May    Jun    Jul    Aug
##    &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 Abandoned Ve~ 0.0890  0.0727  0.0769 0.0710 0.0830 0.0793 0.0778 0.101 
##  2 Barking Dog   0.0563  0.0608  0.0608 0.0631 0.104  0.101  0.0788 0.113 
##  3 Board Up (PL~ 0.0395  0.0482  0.0658 0.0943 0.114  0.0899 0.110  0.123 
##  4 Broken Sidew~ 0.0337  0.155   0.148  0.0872 0.105  0.0964 0.0696 0.0735
##  5 Building Mai~ 0.0708  0.0919  0.103  0.0739 0.0842 0.0829 0.0725 0.0919
##  6 Building Wit~ 0.0842  0.0697  0.0636 0.0577 0.105  0.0883 0.0924 0.0815
##  7 Catch Basin,~ 0.0636  0.0377  0.0778 0.0748 0.0984 0.132  0.0825 0.127 
##  8 City Source ~ 0.00527 0.00246 0.0105 0.0428 0.196  0.213  0.195  0.164 
##  9 City Steps, ~ 0.0443  0.0180  0.0148 0.0197 0.116  0.216  0.203  0.146 
## 10 City Steps, ~ 0.0265  0.0305  0.0713 0.0509 0.128  0.120  0.136  0.128 
## # ... with 74 more rows, and 4 more variables: Sep &lt;dbl&gt;, Oct &lt;dbl&gt;,
## #   Nov &lt;dbl&gt;, Dec &lt;dbl&gt;</code></pre>
<p>Check that they all add up to 1 across the rows</p>
<pre class="r"><code>(df_months %&gt;% 
  select(Jan:Dec) %&gt;% 
  mutate(row_sum = rowSums(.)) %&gt;% 
  select(row_sum, everything()) -&gt; test)</code></pre>
<pre><code>## # A tibble: 84 x 13
##    row_sum     Jan     Feb    Mar    Apr    May    Jun    Jul    Aug
##      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1       1 0.0890  0.0727  0.0769 0.0710 0.0830 0.0793 0.0778 0.101 
##  2       1 0.0563  0.0608  0.0608 0.0631 0.104  0.101  0.0788 0.113 
##  3       1 0.0395  0.0482  0.0658 0.0943 0.114  0.0899 0.110  0.123 
##  4       1 0.0337  0.155   0.148  0.0872 0.105  0.0964 0.0696 0.0735
##  5       1 0.0708  0.0919  0.103  0.0739 0.0842 0.0829 0.0725 0.0919
##  6       1 0.0842  0.0697  0.0636 0.0577 0.105  0.0883 0.0924 0.0815
##  7       1 0.0636  0.0377  0.0778 0.0748 0.0984 0.132  0.0825 0.127 
##  8       1 0.00527 0.00246 0.0105 0.0428 0.196  0.213  0.195  0.164 
##  9       1 0.0443  0.0180  0.0148 0.0197 0.116  0.216  0.203  0.146 
## 10       1 0.0265  0.0305  0.0713 0.0509 0.128  0.120  0.136  0.128 
## # ... with 74 more rows, and 4 more variables: Sep &lt;dbl&gt;, Oct &lt;dbl&gt;,
## #   Nov &lt;dbl&gt;, Dec &lt;dbl&gt;</code></pre>
<div id="perform-basic-comparisons" class="section level3">
<h3>Perform basic comparisons</h3>
<pre class="r"><code>df_months %&gt;% 
  ggplot(aes(Jan, Jul, label = request_type)) +
  geom_point()</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Remember that each dot represents a request type, and the month shows what % of that request type occurred that month</p>
<pre class="r"><code>df_months %&gt;% 
  ggplot(aes(Apr, Oct, label = request_type)) +
  geom_point()</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>It is not feasible to plot all the months against each other. PCA can help by condensing the columns and increasing the variance. PCA creates eigenvectors that represents the data in a concentrated way. Eigenvectors and eigenvalues do not represent observed data. They are calculated representations of the data. We will refer to eigenvectors as “principal components”.</p>
<p>In this case, where our data is measured by months in a year, each principal component could loosely be compared to a season.</p>
</div>
</div>
<div id="prep-the-data-for-pca" class="section level2">
<h2>Prep the data for PCA</h2>
<p>The PCA function requires an all-numeric dataframe, so drop the request types into the dataframe metadata</p>
<pre class="r"><code>(df_months %&gt;% 
  ungroup() %&gt;% 
  remove_rownames() %&gt;% 
  column_to_rownames(var = &quot;request_type&quot;) -&gt; df_months_pca1)</code></pre>
<pre><code>## # A tibble: 84 x 12
##        Jan     Feb    Mar    Apr    May    Jun    Jul    Aug    Sep    Oct
##  *   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
##  1 0.0890  0.0727  0.0769 0.0710 0.0830 0.0793 0.0778 0.101  0.0893 0.0972
##  2 0.0563  0.0608  0.0608 0.0631 0.104  0.101  0.0788 0.113  0.124  0.113 
##  3 0.0395  0.0482  0.0658 0.0943 0.114  0.0899 0.110  0.123  0.0855 0.0877
##  4 0.0337  0.155   0.148  0.0872 0.105  0.0964 0.0696 0.0735 0.0528 0.0849
##  5 0.0708  0.0919  0.103  0.0739 0.0842 0.0829 0.0725 0.0919 0.0776 0.0787
##  6 0.0842  0.0697  0.0636 0.0577 0.105  0.0883 0.0924 0.0815 0.0829 0.113 
##  7 0.0636  0.0377  0.0778 0.0748 0.0984 0.132  0.0825 0.127  0.105  0.0931
##  8 0.00527 0.00246 0.0105 0.0428 0.196  0.213  0.195  0.164  0.0808 0.0583
##  9 0.0443  0.0180  0.0148 0.0197 0.116  0.216  0.203  0.146  0.118  0.0557
## 10 0.0265  0.0305  0.0713 0.0509 0.128  0.120  0.136  0.128  0.108  0.0855
## # ... with 74 more rows, and 2 more variables: Nov &lt;dbl&gt;, Dec &lt;dbl&gt;</code></pre>
<p>Create the PCA object</p>
<pre class="r"><code>(df_months_pca1 %&gt;% 
  prcomp(scale = TRUE) -&gt; pc)</code></pre>
<pre><code>## Standard deviations (1, .., p=12):
##  [1] 2.0313544303132324842 1.5112299607905623766 1.3677583442481697773
##  [4] 1.0647449915481701499 0.9373153843502736171 0.6612690017981472934
##  [7] 0.6319678449167117629 0.5732234023111663079 0.4666060722915733039
## [10] 0.4192405535100036107 0.3847717270238655840 0.0000000000000003789
## 
## Rotation (n x k) = (12 x 12):
##         PC1     PC2       PC3      PC4      PC5        PC6      PC7
## Jan -0.3509  0.2377  0.036588 -0.40554  0.40259 -0.0878343  0.04648
## Feb -0.2189  0.2230 -0.226391  0.69886 -0.14610  0.1005237  0.15306
## Mar -0.0235 -0.4858 -0.323760  0.11519  0.19761 -0.1724337 -0.62037
## Apr  0.1329 -0.4686 -0.301500 -0.04306  0.07313 -0.5014973  0.54199
## May  0.2339 -0.1448 -0.445597 -0.33914 -0.15507  0.5723879 -0.10942
## Jun  0.4049  0.1866  0.002112 -0.22765 -0.21210 -0.0386388  0.13438
## Jul  0.4322  0.1697  0.095923 -0.10888 -0.01800 -0.1443989  0.02032
## Aug  0.3866  0.1805  0.189907  0.17598 -0.04242 -0.2554247 -0.44835
## Sep  0.2944 -0.1580  0.365255  0.16856  0.42595 -0.0005222  0.04916
## Oct  0.1150 -0.4130  0.389922  0.16708  0.17452  0.5136274  0.18989
## Nov -0.1323 -0.3291  0.333424 -0.05855 -0.69855 -0.1384698 -0.02866
## Dec -0.3720 -0.1311  0.333522 -0.25017 -0.03408 -0.0524049 -0.15824
##          PC8       PC9     PC10      PC11   PC12
## Jan -0.10077  0.119474  0.19207  0.310620 0.5699
## Feb  0.04311 -0.085692 -0.10149 -0.130098 0.5209
## Mar -0.31077 -0.259371 -0.01955  0.035606 0.1620
## Apr  0.09929  0.264116 -0.01396 -0.143422 0.1379
## May  0.40042  0.106727 -0.02849 -0.028027 0.2717
## Jun -0.42038 -0.373786  0.36939 -0.413396 0.2471
## Jul -0.13081 -0.103405 -0.77442  0.256091 0.2205
## Aug  0.13536  0.607417  0.20278 -0.123033 0.1983
## Sep  0.53195 -0.454920  0.16862  0.035475 0.1519
## Oct -0.43757  0.304459 -0.02271 -0.003209 0.1456
## Nov  0.09659 -0.104258  0.14115  0.387838 0.2472
## Dec  0.15902 -0.008971 -0.35391 -0.678722 0.1743</code></pre>
<p>Inspect the PCA object with tidier functions from the broom library. These functions turn the PCA object into a tidy dataframe</p>
<pre class="r"><code>pc %&gt;% 
  tidy() %&gt;% 
  head()</code></pre>
<pre><code>##                                    row PC   value
## 1 Abandoned Vehicle (parked on street)  1 -0.8438
## 2                          Barking Dog  1  0.4025
## 3       Board Up (PLI referral to DPW)  1  0.3519
## 4                      Broken Sidewalk  1 -0.7893
## 5                 Building Maintenance  1 -1.1954
## 6            Building Without a Permit  1 -0.7467</code></pre>
<pre class="r"><code>pc %&gt;% 
  tidy(&quot;pcs&quot;)</code></pre>
<pre><code>##    PC               std.dev percent cumulative
## 1   1 2.0313544303132324842 0.34387     0.3439
## 2   2 1.5112299607905623766 0.19032     0.5342
## 3   3 1.3677583442481697773 0.15590     0.6901
## 4   4 1.0647449915481701499 0.09447     0.7846
## 5   5 0.9373153843502736171 0.07321     0.8578
## 6   6 0.6612690017981472934 0.03644     0.8942
## 7   7 0.6319678449167117629 0.03328     0.9275
## 8   8 0.5732234023111663079 0.02738     0.9549
## 9   9 0.4666060722915733039 0.01814     0.9730
## 10 10 0.4192405535100036107 0.01465     0.9877
## 11 11 0.3847717270238655840 0.01234     1.0000
## 12 12 0.0000000000000003789 0.00000     1.0000</code></pre>
<pre class="r"><code>pc %&gt;% 
  augment(data = df_months) -&gt; au

au %&gt;% 
  head()</code></pre>
<pre><code>##   .rownames                         request_type     Jan     Feb     Mar
## 1         1 Abandoned Vehicle (parked on street) 0.08899 0.07266 0.07691
## 2         2                          Barking Dog 0.05631 0.06081 0.06081
## 3         3       Board Up (PLI referral to DPW) 0.03947 0.04825 0.06579
## 4         4                      Broken Sidewalk 0.03366 0.15455 0.14767
## 5         5                 Building Maintenance 0.07078 0.09189 0.10335
## 6         6            Building Without a Permit 0.08424 0.06971 0.06358
##       Apr     May     Jun     Jul     Aug     Sep     Oct     Nov     Dec
## 1 0.07095 0.08304 0.07929 0.07776 0.10141 0.08933 0.09716 0.08610 0.07640
## 2 0.06306 0.10360 0.10135 0.07883 0.11261 0.12387 0.11261 0.07432 0.05180
## 3 0.09430 0.11404 0.08991 0.10965 0.12281 0.08553 0.08772 0.07675 0.06579
## 4 0.08722 0.10482 0.09640 0.06963 0.07345 0.05279 0.08493 0.06427 0.03060
## 5 0.07393 0.08415 0.08291 0.07250 0.09189 0.07756 0.07871 0.09342 0.07890
## 6 0.05767 0.10490 0.08833 0.09242 0.08152 0.08288 0.11285 0.08629 0.07561
##   .fittedPC1 .fittedPC2 .fittedPC3 .fittedPC4 .fittedPC5 .fittedPC6
## 1    -0.8438    -0.8440     0.3834    0.31097    0.20612    0.06198
## 2     0.4025    -0.6984     0.8682    0.60695    0.61193    0.81193
## 3     0.3519    -0.7932    -0.1726    0.01697   -0.09451   -0.36009
## 4    -0.7893    -1.6360    -2.3663    1.08896    0.02600   -0.16345
## 5    -1.1954    -1.0895    -0.3846    0.34539   -0.12184   -0.38704
## 6    -0.7467    -0.6709     0.5604    0.02265   -0.01962    1.00834
##   .fittedPC7 .fittedPC8 .fittedPC9 .fittedPC10 .fittedPC11
## 1    -0.1804    -0.0300    0.05695     0.02524    -0.09236
## 2     0.1265     0.3788   -0.21070     0.61620     0.06686
## 3     0.1801     0.3399    0.58067    -0.38215    -0.19208
## 4    -0.7529    -1.4068   -0.53036     0.13288     0.22951
## 5    -0.6769    -0.2008   -0.37650    -0.02991    -0.19275
## 6     0.1325    -0.3432   -0.07738    -0.32705     0.02680
##               .fittedPC12
## 1  0.00000000000000001388
## 2 -0.00000000000000004857
## 3  0.00000000000000002776
## 4  0.00000000000000063838
## 5 -0.00000000000000006939
## 6 -0.00000000000000031919</code></pre>
<p>Plot how the PCA object explains the variance in the data</p>
<pre class="r"><code>pc %&gt;% 
  tidy(&quot;pcs&quot;) %&gt;%
  select(-std.dev) %&gt;% 
  gather(measure, value, -PC) %&gt;% 
    ggplot(aes(PC, value)) +
    geom_line() +
    geom_point() +
    facet_wrap(~measure) +
    labs(title = &quot;Variance explained by each principal component&quot;,
         x = &quot;Principle Component&quot;,
         y = NULL) +
    scale_x_continuous(breaks = 1:12)</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>The first two principal components explain most of the variance</p>
<p>For an in-depth plot we need to create the PCA object a different way</p>
<pre class="r"><code>df_months %&gt;% 
  nest() %&gt;% 
  mutate(pca = map(data, ~ prcomp(.x %&gt;% select(-request_type), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y))) -&gt; df_months_pca2</code></pre>
<p>Plot the PCA data</p>
<pre class="r"><code>df_months_pca2 %&gt;%
  mutate(
    pca_graph = map2(
      .x = pca,
      .y = data,
      ~ autoplot(.x, loadings = TRUE, loadings.label = TRUE,
                 loadings.label.repel = TRUE,
                 data = .y) +
        theme_bw() +
        labs(x = &quot;Principal Component 1&quot;,
             y = &quot;Principal Component 2&quot;,
             title = &quot;First two principal components of PCA on 311 dataset&quot;)
    )
  ) %&gt;%
  pull(pca_graph)</code></pre>
<pre><code>## [[1]]</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>This shows that summer and winter explain a significant part of the variance</p>
<p>Plot the data to show the outliers</p>
<pre class="r"><code>au %&gt;% 
  mutate(outlier = case_when(abs(.fittedPC1) &gt; 2 &amp; abs(.fittedPC2) &gt; 1.5 ~ TRUE)) -&gt; au

au %&gt;% 
ggplot(aes(.fittedPC1, .fittedPC2)) +
  geom_point() +
  geom_label_repel(data = au %&gt;% filter(outlier),
             aes(label = request_type)) +
  theme_bw()</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code>au %&gt;% 
ggplot(aes(.fittedPC1, .fittedPC2)) +
  geom_point() +
  geom_label_repel(data = au %&gt;% filter(request_type == &quot;Potholes&quot;),
             aes(label = request_type)) +
  theme_bw()</code></pre>
<p><img src="/post/2018-07-15-exploring-311-data-with-pca_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
</div>
</div>
<div id="sources" class="section level1">
<h1>Sources</h1>
<ul>
<li><a href="https://tbradley1013.github.io/2018/02/01/pca-in-a-tidy-verse-framework/" class="uri">https://tbradley1013.github.io/2018/02/01/pca-in-a-tidy-verse-framework/</a></li>
<li><a href="https://rdrr.io/cran/broom/man/prcomp_tidiers.html" class="uri">https://rdrr.io/cran/broom/man/prcomp_tidiers.html</a></li>
<li><a href="https://poissonisfish.wordpress.com/2017/01/23/principal-component-analysis-in-r/" class="uri">https://poissonisfish.wordpress.com/2017/01/23/principal-component-analysis-in-r/</a></li>
<li><a href="http://rstatistics.net/principal-component-analysis/" class="uri">http://rstatistics.net/principal-component-analysis/</a></li>
<li><a href="https://community.rstudio.com/t/tidyverse-solutions-for-factor-analysis-principal-component-analysis/4504" class="uri">https://community.rstudio.com/t/tidyverse-solutions-for-factor-analysis-principal-component-analysis/4504</a></li>
</ul>
</div>
